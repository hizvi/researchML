{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_edus import EDUSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> DATA LOADED\n"
     ]
    }
   ],
   "source": [
    "data = EDUSample()\n",
    "path = r'../LabeledEDUS_final.txt'\n",
    "\n",
    "edus, targets = data.read_labeled(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Embedding, Conv1D, Dropout, MaxPooling1D, GlobalMaxPooling1D, LSTM, TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_PATH = r'../../../GloVe/glove.6B.100d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize edus\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(edus)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "\n",
    "# integer encode the documents\n",
    "encoded_edus = t.texts_to_sequences(edus)\n",
    "\n",
    "# max_length = 1 << (max(map(lambda x: len(x), encoded_edus)) - 1).bit_length()  # pad to smallest power of 2 greater than the largest edu\n",
    "max_length = sum(map(lambda x: len(x), encoded_edus)) // len(encoded_edus)       # pad to the average length of edus\n",
    "padded_edus = pad_sequences(encoded_edus, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = data.split_data(padded_edus, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing embedding matrix.\n",
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "print('Preparing embedding matrix.')\n",
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open(GLOVE_PATH)\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using regularization \n",
    "regularizer = None\n",
    "regularization = True\n",
    "dropout = True\n",
    "if regularization:\n",
    "    regularizer = l1(0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Setup\n",
      "Fitting model\n",
      "Epoch 1/5\n",
      "2266/2266 [==============================] - 28s 12ms/step - loss: 0.6229 - acc: 0.7184\n",
      "Epoch 2/5\n",
      "2266/2266 [==============================] - 24s 11ms/step - loss: 0.5012 - acc: 0.8094\n",
      "Epoch 3/5\n",
      "2266/2266 [==============================] - 29s 13ms/step - loss: 0.4652 - acc: 0.8222\n",
      "Epoch 4/5\n",
      "2266/2266 [==============================] - 30s 13ms/step - loss: 0.4372 - acc: 0.8451\n",
      "Epoch 5/5\n",
      "2266/2266 [==============================] - 28s 12ms/step - loss: 0.4096 - acc: 0.8544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcc403d1588>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Model Setup') \n",
    "\n",
    "inputs = Input(shape=(max_length,), dtype='int32')\n",
    "embed_sequence = Embedding(vocab_size, 100, \n",
    "                           #weights=[embedding_matrix],\n",
    "                           embeddings_initializer=Constant(embedding_matrix), \n",
    "                           input_length=max_length,\n",
    "                           trainable=False)(inputs)\n",
    "\n",
    "x = LSTM(32, return_sequences=False, kernel_regularizer=regularizer)(embed_sequence)\n",
    "\n",
    "if dropout:\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "preds = Dense(1, activation='sigmoid', name='output_layer', kernel_regularizer=regularizer)(x)\n",
    "\n",
    "model = Model(inputs, preds)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "\n",
    "print('Fitting model')\n",
    "model.fit(X_train, y_train, \n",
    "          epochs=5,\n",
    "          batch_size=1\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(X_test)\n",
    "results = np.array([0 if r < 0.5 else 1 for r in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1133/1133 [==============================] - 1s 723us/step\n",
      "2266/2266 [==============================] - 0s 89us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.5164633674739424, 0.79523389258431],\n",
       " [0.36981119103696847, 0.8693733448910692])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# m = model.evaluate(X_test, y_test)\n",
    "model.evaluate(X_test, y_test), model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.799771167048055"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7993257155431213, 0.8, 0.7994853084806113, None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_test, results, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(zip(model.predict(X_train), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"337pt\" viewBox=\"0.00 0.00 211.00 337.00\" width=\"211pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 333)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-333 207,-333 207,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 139694968648872 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>139694968648872</title>\n",
       "<polygon fill=\"none\" points=\"21.5,-292.5 21.5,-328.5 181.5,-328.5 181.5,-292.5 21.5,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"101.5\" y=\"-306.8\">input_2: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139694968651224 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>139694968651224</title>\n",
       "<polygon fill=\"none\" points=\"0,-219.5 0,-255.5 203,-255.5 203,-219.5 0,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"101.5\" y=\"-233.8\">embedding_1: Embedding</text>\n",
       "</g>\n",
       "<!-- 139694968648872&#45;&gt;139694968651224 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>139694968648872-&gt;139694968651224</title>\n",
       "<path d=\"M101.5,-292.4551C101.5,-284.3828 101.5,-274.6764 101.5,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"105.0001,-265.5903 101.5,-255.5904 98.0001,-265.5904 105.0001,-265.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139694968649096 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>139694968649096</title>\n",
       "<polygon fill=\"none\" points=\"37.5,-146.5 37.5,-182.5 165.5,-182.5 165.5,-146.5 37.5,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"101.5\" y=\"-160.8\">dense_1: Dense</text>\n",
       "</g>\n",
       "<!-- 139694968651224&#45;&gt;139694968649096 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>139694968651224-&gt;139694968649096</title>\n",
       "<path d=\"M101.5,-219.4551C101.5,-211.3828 101.5,-201.6764 101.5,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"105.0001,-192.5903 101.5,-182.5904 98.0001,-192.5904 105.0001,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139694968649768 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>139694968649768</title>\n",
       "<polygon fill=\"none\" points=\"39,-73.5 39,-109.5 164,-109.5 164,-73.5 39,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"101.5\" y=\"-87.8\">flatten: Flatten</text>\n",
       "</g>\n",
       "<!-- 139694968649096&#45;&gt;139694968649768 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>139694968649096-&gt;139694968649768</title>\n",
       "<path d=\"M101.5,-146.4551C101.5,-138.3828 101.5,-128.6764 101.5,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"105.0001,-119.5903 101.5,-109.5904 98.0001,-119.5904 105.0001,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139694701636576 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>139694701636576</title>\n",
       "<polygon fill=\"none\" points=\"21,-.5 21,-36.5 182,-36.5 182,-.5 21,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"101.5\" y=\"-14.8\">output_layer: Dense</text>\n",
       "</g>\n",
       "<!-- 139694968649768&#45;&gt;139694701636576 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>139694968649768-&gt;139694701636576</title>\n",
       "<path d=\"M101.5,-73.4551C101.5,-65.3828 101.5,-55.6764 101.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"105.0001,-46.5903 101.5,-36.5904 98.0001,-46.5904 105.0001,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
